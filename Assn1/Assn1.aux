\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Random Numbers}{1}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Gaussian distributions constructed from the accept/reject method (the blue histogram) and analytically (the black line). The Gaussians have mean $\mu =5$ and standard deviation $\sigma =1.25$.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Gauss_Dist}{{1}{2}{Gaussian distributions constructed from the accept/reject method (the blue histogram) and analytically (the black line). The Gaussians have mean $\mu =5$ and standard deviation $\sigma =1.25$.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Distribution of a number $s$ calculated by summing 10 numbers from a Gaussian distribution. The blue histogram shows the distribution of samples while the black line shows a Gaussian distribution constructed from parameters of the data.\relax }}{2}{figure.caption.2}}
\newlabel{fig:Gauss_sum}{{2}{2}{Distribution of a number $s$ calculated by summing 10 numbers from a Gaussian distribution. The blue histogram shows the distribution of samples while the black line shows a Gaussian distribution constructed from parameters of the data.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Markov Chain}{2}{subsection.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Cumulative Distribution function at different times $t$.\relax }}{3}{table.caption.3}}
\newlabel{tab:CDF}{{1}{3}{Cumulative Distribution function at different times $t$.\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Markov Chain Monte Carlo}{3}{subsection.2.3}}
\newlabel{lilgauss}{{4}{3}{Markov Chain Monte Carlo}{equation.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces First 400 values generated by a Markov chain Monte Carlo algorithm. The mean of the proceeding values is tracked by the orange line. The mean asymptotically approaches the expected mean of $x=0$ over time. Random steps were selected using a uniform distribution from $(-\sigma , \sigma )$ where $\sigma $ was the standard distribution of the Gaussian distribution being sampled.\relax }}{4}{figure.caption.4}}
\newlabel{fig:MCMCmean}{{3}{4}{First 400 values generated by a Markov chain Monte Carlo algorithm. The mean of the proceeding values is tracked by the orange line. The mean asymptotically approaches the expected mean of $x=0$ over time. Random steps were selected using a uniform distribution from $(-\sigma , \sigma )$ where $\sigma $ was the standard distribution of the Gaussian distribution being sampled.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Distribution of a 5000 sample Gaussian sampling. Samples were drawn from the distribution in equation \ref  {lilgauss}.\relax }}{4}{figure.caption.5}}
\newlabel{fig:MCMChisto}{{4}{4}{Distribution of a 5000 sample Gaussian sampling. Samples were drawn from the distribution in equation \ref {lilgauss}.\relax }{figure.caption.5}{}}
\newlabel{PDF}{{5}{4}{Markov Chain Monte Carlo}{equation.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A probability distribution function defined by equation \ref  {PDF}\relax }}{5}{figure.caption.6}}
\newlabel{fig:PDF}{{5}{5}{A probability distribution function defined by equation \ref {PDF}\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Samples from distribution \ref  {PDF} using two different proposal distributions. In the upper histogram, a uniform distribution was used. In the bottom, a $\chi ^2$ distribution was used. The plots were cropped from the range $(0,100)$ to $(0,30)$ to better show features near the origin. The uniform histogram has wider bins due to the high number of counts far from the origin. The $\chi ^2$ histogram had an 'unlucky' spike past $x=10$ due to random draws.\relax }}{5}{figure.caption.7}}
\newlabel{fig:mixed_chains}{{6}{5}{Samples from distribution \ref {PDF} using two different proposal distributions. In the upper histogram, a uniform distribution was used. In the bottom, a $\chi ^2$ distribution was used. The plots were cropped from the range $(0,100)$ to $(0,30)$ to better show features near the origin. The uniform histogram has wider bins due to the high number of counts far from the origin. The $\chi ^2$ histogram had an 'unlucky' spike past $x=10$ due to random draws.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Potentail well in equation \ref  {eq:well} visualized near minima of interest.\relax }}{5}{figure.caption.8}}
\newlabel{fig:PotentialWell}{{7}{5}{Potentail well in equation \ref {eq:well} visualized near minima of interest.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Simulated Annealing}{5}{subsection.2.4}}
\newlabel{eq:well}{{7}{5}{Simulated Annealing}{equation.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Annealing performed on equation \ref  {eq:well} to determine local minima. Algorithm was performed at a single temperature $T=1$ for multiple steps. The plot on the left shows each step of the random walker. The plot on the right shows the histogram of walker position.\relax }}{6}{figure.caption.9}}
\newlabel{fig:annealT1}{{8}{6}{Annealing performed on equation \ref {eq:well} to determine local minima. Algorithm was performed at a single temperature $T=1$ for multiple steps. The plot on the left shows each step of the random walker. The plot on the right shows the histogram of walker position.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Traveling Salesman}{6}{subsection.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Annealing algorithm at a single temperature $T=0.4$ for multiple steps. The plots are layed out as in \ref  {fig:annealT1}.\relax }}{6}{figure.caption.10}}
\newlabel{fig:annealT04}{{9}{6}{Annealing algorithm at a single temperature $T=0.4$ for multiple steps. The plots are layed out as in \ref {fig:annealT1}.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Annealing algorithm performed at a single temperature $T=0.001$ for multiple steps. The plots are layed out as in \ref  {fig:annealT1}.\relax }}{6}{figure.caption.11}}
\newlabel{fig:annealT01}{{10}{6}{Annealing algorithm performed at a single temperature $T=0.001$ for multiple steps. The plots are layed out as in \ref {fig:annealT1}.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Location of a global minimum using annealing. A linear temperature schedule from $T=1$ to $T=0.01$ was used. The plots are layed out as in \ref  {fig:annealT1}.\relax }}{6}{figure.caption.12}}
\newlabel{fig:anneal_full}{{11}{6}{Location of a global minimum using annealing. A linear temperature schedule from $T=1$ to $T=0.01$ was used. The plots are layed out as in \ref {fig:annealT1}.\relax }{figure.caption.12}{}}
\bibcite{ouyed}{1}
\bibcite{NR}{2}
\bibcite{Code}{3}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Distances between 5 cities used in a traveling salesman problem.\relax }}{7}{table.caption.13}}
\newlabel{tab:5cities}{{2}{7}{Distances between 5 cities used in a traveling salesman problem.\relax }{table.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Visualization of the greedy method. The method is initialized to start in city 3 in this simulation. In frame 1, the algorithm begins checking the distance from 3 to each other city, starting with 0. Frame 2 shows two steps later, when the algorithm checks the distance of $3 \to 2$ and compares this to the best previous result ($3 \to 0$). In frame 5, the route $3 \to 0$ was selected as the best first segment, and it begins sequentially checking next segments beginning with $0 \to 1$. Frame 10 shows the final result by this method.\relax }}{7}{figure.caption.14}}
\newlabel{fig:greedy_4frames}{{12}{7}{Visualization of the greedy method. The method is initialized to start in city 3 in this simulation. In frame 1, the algorithm begins checking the distance from 3 to each other city, starting with 0. Frame 2 shows two steps later, when the algorithm checks the distance of $3 \to 2$ and compares this to the best previous result ($3 \to 0$). In frame 5, the route $3 \to 0$ was selected as the best first segment, and it begins sequentially checking next segments beginning with $0 \to 1$. Frame 10 shows the final result by this method.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Discussion}{7}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{7}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The brute force method checked every possible permulation of the five city route. Four of the possible permutations were shown here. Frame 61 was found to be the optimal route by this method.\relax }}{8}{figure.caption.15}}
\newlabel{fig:brute_4frames}{{13}{8}{The brute force method checked every possible permulation of the five city route. Four of the possible permutations were shown here. Frame 61 was found to be the optimal route by this method.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Visualization of the annealing method. In frame 01, a simple route was initialized. At each step, a new neighbor configuration was proposed. In frame 02, the positions of cities 0 and 4 were swapped. This configuration was accepted due to being lower total distance. Next, cities 1 and 2 were swapped. At low temperature, this move was accepted, even though it was a longer distance. In frame 05, the cities have found the lowest distance state of the run.\relax }}{8}{figure.caption.16}}
\newlabel{fig:anneal_4frames}{{14}{8}{Visualization of the annealing method. In frame 01, a simple route was initialized. At each step, a new neighbor configuration was proposed. In frame 02, the positions of cities 0 and 4 were swapped. This configuration was accepted due to being lower total distance. Next, cities 1 and 2 were swapped. At low temperature, this move was accepted, even though it was a longer distance. In frame 05, the cities have found the lowest distance state of the run.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix}{8}{section.5}}
